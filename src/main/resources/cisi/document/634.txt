   It was argued in Part I (see JASIS, March-April 1973 p. 87) that the bestway to evaluate a retrieval system is, in principle at least, to elicitsubjective estimates of the system's utility to its users, quantified interms of the numbers of utilities (e.g. dollars) they would have been willingto give up in exchange for the privilege of using the system; and a naivemethodology was outlined for evaluating retrieval systems on this basis..But the impracticality of the naive evaluation procedure as it stands raisesthe questions:	How can one decide which practical measure is likely toyield results most closely resembling those of the naive methodology? Andhow can one tell whether the resemblance is close enough to make applyingthe measure worth while? In the present paper two kinds of solution tothese problems are taken up.. The first answers the questions in termsof the reasonableness of the simplifying assumptions needed to get fromthe naive measure to the proposed substitute.. The second answers it byexperimentation..